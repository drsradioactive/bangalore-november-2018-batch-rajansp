{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyfMmMnPJjvn"
   },
   "source": [
    "## Train a simple convnet on the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjcGOJhcJjvp"
   },
   "source": [
    "In this, we will see how to deal with image data and train a convnet for image classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR0Pl2XjJjvq"
   },
   "source": [
    "### Load the  `fashion_mnist`  dataset\n",
    "\n",
    "** Use keras.datasets to load the dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr75v_UYJjvs"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTI42-0qJjvw"
   },
   "source": [
    "### Find no.of samples are there in training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2sf67VoJjvx",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training examples X:  60000\n",
      "Number of Training examples Y:  60000\n"
     ]
    }
   ],
   "source": [
    "print('Number of Training examples X: ', x_train.shape[0])\n",
    "print('Number of Training examples Y: ', y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test examples X:  10000\n",
      "Number of Test examples Y:  10000\n"
     ]
    }
   ],
   "source": [
    "print('Number of Test examples X: ', x_test.shape[0])\n",
    "print('Number of Test examples Y: ', y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WytT2eRnJjv4"
   },
   "source": [
    "### Find dimensions of an image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XycQGBSGJjv5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the below image: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# visualizing the first image in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1)) #width 10, height 1\n",
    "\n",
    "plt.subplot(1, 10, 1)\n",
    "plt.imshow(x_train[0].reshape(28, 28), cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "print('label for each of the below image: %s' % (np.argmax(y_train[0:10][1])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jtdZ7RqJjv8"
   },
   "source": [
    "### Convert train and test labels to one hot vectors\n",
    "\n",
    "** check `keras.utils.to_categorical()` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAD3q5I6Jjv9"
   },
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgHSCXy3JjwA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training examples Y:  60000\n",
      "Number of Test examples Y:  10000\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Number of Training examples Y: ', y_train.shape[0])\n",
    "print('Number of Test examples Y: ', y_test.shape[0])\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xO5BRBzBJjwD"
   },
   "source": [
    "### Normalize both the train and test image data from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fUQpMHxJjwE"
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da5-DwgrJjwM"
   },
   "source": [
    "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPGVQ-JJJjwN"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFRRTJq8JjwQ"
   },
   "source": [
    "### Import the necessary layers from keras to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWTZYnKSJjwR"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C18AoS7eJjwU"
   },
   "source": [
    "### Build a model \n",
    "\n",
    "** with 2 Conv layers having `32 3*3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DORCLgSwJjwV"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "#Normalize the data\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Conv2D(33, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "#Normalize the data\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "# Add Flatten before passing the feature map into 2 fully connected layers\n",
    "model.add(Flatten())\n",
    "#Hidden layers\n",
    "model.add(Dense(128, activation='relu', name='Layer_1'))\n",
    "model.add(Dense(10, activation='softmax', name='Layer_2'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# patient early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 33)        9537      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24, 24, 33)        132       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 19008)             0         \n",
      "_________________________________________________________________\n",
      "Layer_1 (Dense)              (None, 128)               2433152   \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,444,559\n",
      "Trainable params: 2,444,429\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 267s 4ms/step - loss: 0.4490 - acc: 0.8573 - val_loss: 0.3454 - val_acc: 0.8844\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 265s 4ms/step - loss: 0.2537 - acc: 0.9084 - val_loss: 0.3027 - val_acc: 0.8953\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 273s 5ms/step - loss: 0.2013 - acc: 0.9266 - val_loss: 0.3061 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 276s 5ms/step - loss: 0.1587 - acc: 0.9420 - val_loss: 0.2915 - val_acc: 0.9073\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 280s 5ms/step - loss: 0.1247 - acc: 0.9541 - val_loss: 0.3470 - val_acc: 0.9038\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 282s 5ms/step - loss: 0.1050 - acc: 0.9616 - val_loss: 0.3833 - val_acc: 0.9097\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 281s 5ms/step - loss: 0.0922 - acc: 0.9679 - val_loss: 0.4802 - val_acc: 0.8984\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0770 - acc: 0.9725 - val_loss: 0.3908 - val_acc: 0.8966\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0647 - acc: 0.9769 - val_loss: 0.4905 - val_acc: 0.9088\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18b9acf1eb8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, validation_data=(x_test,y_test), epochs=10, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ju69vKdIJjwX"
   },
   "source": [
    "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2hAP94vJjwY"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "#Normalize the data\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Conv2D(33, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "#Normalize the data\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "# Add MaxPooling2D and Dropput after the convolution layers\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "#Hidden layers\n",
    "model.add(Dense(128, activation='relu', name='Layer_1'))\n",
    "model.add(Dense(10, activation='softmax', name='Layer_2'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the Model and Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# patient early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 33)        9537      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 24, 24, 33)        132       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 33)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 33)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4752)              0         \n",
      "_________________________________________________________________\n",
      "Layer_1 (Dense)              (None, 128)               608384    \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 619,791\n",
      "Trainable params: 619,661\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 507s 8ms/step - loss: 0.3912 - acc: 0.8639 - val_loss: 0.3085 - val_acc: 0.8882\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 659s 11ms/step - loss: 0.2570 - acc: 0.9061 - val_loss: 0.3196 - val_acc: 0.8857\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 501s 8ms/step - loss: 0.2148 - acc: 0.9203 - val_loss: 0.3269 - val_acc: 0.8907\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.1886 - acc: 0.9304 - val_loss: 0.2663 - val_acc: 0.9110\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 258s 4ms/step - loss: 0.1637 - acc: 0.9395 - val_loss: 0.2568 - val_acc: 0.9113\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 256s 4ms/step - loss: 0.1473 - acc: 0.9458 - val_loss: 0.2514 - val_acc: 0.9188\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 246s 4ms/step - loss: 0.1298 - acc: 0.9518 - val_loss: 0.2522 - val_acc: 0.9205\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 248s 4ms/step - loss: 0.1141 - acc: 0.9574 - val_loss: 0.2672 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 245s 4ms/step - loss: 0.1038 - acc: 0.9616 - val_loss: 0.2866 - val_acc: 0.9148\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 246s 4ms/step - loss: 0.0938 - acc: 0.9654 - val_loss: 0.2822 - val_acc: 0.9178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18babb63ac8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, validation_data=(x_test,y_test), epochs=10, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 15s 2ms/step\n",
      "accuracy:  91.78\n",
      "loss:  0.2822371180355549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.78"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test)\n",
    "print('accuracy: ',scores[1]*100)\n",
    "print('loss: ',scores[0])\n",
    "scores[1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Accuracy is 91.78% with loss of 0.28**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
